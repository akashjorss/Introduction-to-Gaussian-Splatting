{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is authored by Akash Malhotra. For any questions please email akash.malhotra@lisn.fr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.distributions import Normal\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following generates synthetic data, which a combination of 3 Gaussian Distributions, with means -2, 0 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load weather data\n",
    "temperatures = pd.read_csv('DailyDelhiClimateTest.csv')['meantemp'].values\n",
    "#plot temperatures\n",
    "plt.plot(temperatures)\n",
    "plt.title('Daily temperatures in Delhi')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We initialize k Gaussian kernels, each with randomly assigned mean, variance and weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize K gaussian kernels and their weights, with means and variances in the range of len(temperatures)\n",
    "def initialize_gaussian_kernels(K, data_length):\n",
    "    means = torch.tensor(np.random.randint(0, data_length, K).astype(float), requires_grad=True)\n",
    "    variances = torch.tensor(np.random.randint(1, data_length, K).astype(float), requires_grad=True)\n",
    "    weights = torch.tensor(np.random.rand(K))\n",
    "    weights = weights / weights.sum()\n",
    "    weights.requires_grad = True\n",
    "\n",
    "    return means, variances, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize K gaussian kernels\n",
    "K = 10\n",
    "data_length = len(temperatures)\n",
    "means, variances, weights = initialize_gaussian_kernels(K, data_length)\n",
    "\n",
    "#plot all the pdfs in one plot\n",
    "x = torch.linspace(0, len(temperatures), len(temperatures))\n",
    "pdfs = []\n",
    "for i in range(K):\n",
    "    pdfs.append(weights[i] * torch.exp(dist.Normal(means[i], variances[i]).log_prob(x)))\n",
    "    plt.plot(x, pdfs[i].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Signal Approximation\n",
    "\n",
    "We approximate this signal $ S(t) $ using $ K $ Gaussian PDFs.\n",
    "\n",
    "A Gaussian is parametrized by $\\mu$ (mean) and $\\sigma$ (standard deviation). Its value at $ t $ is:\n",
    "\n",
    "$$ f(t \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(t - \\mu)^2}{2\\sigma^2}\\right) $$\n",
    "\n",
    "A reconstructed signal $\\hat{S}(t)$ can be represented by Gaussians as:\n",
    "\n",
    "$$ \\hat{S}(t) = \\sum_{i=1}^{K} w_i f_i(t) $$\n",
    "\n",
    "And we can use L2 loss to form gradient descent as follows:\n",
    "\n",
    "$$ \\mathcal{L} = \\frac{1}{T} \\sum_{t=1}^{T} (\\hat{S}(t) - S(t))^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the sum of all pdfs\n",
    "pdf = torch.zeros(len(temperatures))\n",
    "for i in range(K):\n",
    "    pdf += weights[i] * torch.exp(dist.Normal(means[i], variances[i]).log_prob(x))\n",
    "plt.plot(x, pdf.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructed_signal(means, variances, weights):\n",
    "    x = torch.linspace(0, len(temperatures), len(temperatures))\n",
    "    pdf = torch.zeros(len(temperatures))\n",
    "    K = len(means)\n",
    "    for i in range(K):\n",
    "        pdf += weights[i] * torch.exp(dist.Normal(means[i], variances[i]).log_prob(x))\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(original, reconstructed):\n",
    "    mse = torch.mean((original - reconstructed) ** 2)\n",
    "    return 20 * torch.log10(torch.max(original) / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gaussians(means, variances, weights, temperatures, lr=0.1, iterations=100000):\n",
    "    optimizer = torch.optim.Adam([means, variances, weights], lr=lr)\n",
    "    last_loss = None\n",
    "    for i in tqdm(range(iterations), desc=f'Optimizing Gaussians for k={len(means)}'):\n",
    "        optimizer.zero_grad()\n",
    "        pdf = reconstructed_signal(means, variances, weights)\n",
    "        loss = torch.sum((pdf - torch.tensor(temperatures))**2)/len(temperatures)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #clip variances to be positive\n",
    "        variances.data = torch.clamp(variances.data, 0.1, len(temperatures))\n",
    "        \n",
    "        # Check for improvement\n",
    "        # if last_loss is not None and abs(last_loss - loss.item()) < threshold:\n",
    "        #     # print(f'Stopping optimization, loss improvement is less than {threshold}')\n",
    "        #     break\n",
    "        # last_loss = loss.item()\n",
    "        \n",
    "        # if i % 100 == 0:\n",
    "        #     print(loss)\n",
    "    print(f'Final loss: {loss}')\n",
    "    return means, variances, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "means, variances, weights = initialize_gaussian_kernels(k, data_length)\n",
    "means, variances, weights = optimize_gaussians(means, variances, weights, temperatures)\n",
    "pdf = reconstructed_signal(means, variances, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the original signal and the reconstructed signal\n",
    "plt.plot(temperatures)\n",
    "plt.plot(pdf.detach().numpy())\n",
    "plt.title('Temperature in Delhi')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Temperature')\n",
    "plt.legend(['Ground Truth', 'Reconstructed'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs = []\n",
    "for k in range(1, len(temperatures) + 1):\n",
    "    means, variances, weights = initialize_gaussian_kernels(k, data_length)\n",
    "    means, variances, weights = optimize_gaussians(means, variances, weights, temperatures)\n",
    "    pdf = reconstructed_signal(means, variances, weights)\n",
    "    psnrs.append(calculate_psnr(torch.tensor(temperatures), pdf).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the PSNR for different K\n",
    "plt.plot(range(1, len(psnrs)+1), psnrs)\n",
    "plt.title('PSNR for different K')\n",
    "plt.xlabel('Number of Gaussians (K)')\n",
    "plt.ylabel('PSNR')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
