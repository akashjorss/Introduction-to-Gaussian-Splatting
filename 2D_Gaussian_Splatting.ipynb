{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6czy2W0_0owD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import imageio\n",
        "import yaml\n",
        "from torch.optim import Adam\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVURVWiLA_ze"
      },
      "source": [
        "## 2D Gaussian Splatting ##\n",
        "\n",
        "The core function for generating 2D Gaussian Splatting. The core mechanic of this function is as follow\n",
        "\n",
        "> Constructs a 2D Gaussian kernel using provided batch of sigma_x, sigma_y, and rho\n",
        "\\begin{equation} \\sigma_x, \\sigma_y, \\rho\\ \\end{equation}\n",
        "\n",
        "\n",
        "> Normalises and reshapes the kernel to RGB channels, pads to match the image size, and translates based on given coords. Basically poutting the relevant kernel in the relevant coordinate position.\n",
        "\n",
        "\n",
        "> Multiplies the RGB kernels with given colours, sums up the layers, and returns the final clamped and permuted image.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BUCJRA--1zw"
      },
      "outputs": [],
      "source": [
        "def generate_2D_gaussian_splatting(kernel_size, sigma_x, sigma_y, rho, coords, colours, image_size=(256, 256, 3), device=\"cpu\"):\n",
        "\n",
        "    batch_size = colours.shape[0]\n",
        "\n",
        "    sigma_x = sigma_x.view(batch_size, 1, 1)\n",
        "    sigma_y = sigma_y.view(batch_size, 1, 1)\n",
        "    rho = rho.view(batch_size, 1, 1)\n",
        "\n",
        "    covariance = torch.stack(\n",
        "        [torch.stack([sigma_x**2, rho*sigma_x*sigma_y], dim=-1),\n",
        "        torch.stack([rho*sigma_x*sigma_y, sigma_y**2], dim=-1)],\n",
        "        dim=-2\n",
        "    )\n",
        "\n",
        "    # Check for positive semi-definiteness\n",
        "    determinant = (sigma_x**2) * (sigma_y**2) - (rho * sigma_x * sigma_y)**2\n",
        "    if (determinant <= 0).any():\n",
        "        raise ValueError(\"Covariance matrix must be positive semi-definite\")\n",
        "\n",
        "    inv_covariance = torch.inverse(covariance)\n",
        "\n",
        "    # Choosing quite a broad range for the distribution [-5,5] to avoid any clipping\n",
        "    start = torch.tensor([-5.0], device=device).view(-1, 1)\n",
        "    end = torch.tensor([5.0], device=device).view(-1, 1)\n",
        "    base_linspace = torch.linspace(0, 1, steps=kernel_size, device=device)\n",
        "    ax_batch = start + (end - start) * base_linspace\n",
        "\n",
        "    # Expanding dims for broadcasting\n",
        "    ax_batch_expanded_x = ax_batch.unsqueeze(-1).expand(-1, -1, kernel_size)\n",
        "    ax_batch_expanded_y = ax_batch.unsqueeze(1).expand(-1, kernel_size, -1)\n",
        "\n",
        "    # Creating a batch-wise meshgrid using broadcasting\n",
        "    xx, yy = ax_batch_expanded_x, ax_batch_expanded_y\n",
        "\n",
        "    xy = torch.stack([xx, yy], dim=-1)\n",
        "    z = torch.einsum('b...i,b...ij,b...j->b...', xy, -0.5 * inv_covariance, xy)\n",
        "    kernel = torch.exp(z) / (2 * torch.tensor(np.pi, device=device) * torch.sqrt(torch.det(covariance)).view(batch_size, 1, 1))\n",
        "\n",
        "\n",
        "    kernel_max_1, _ = kernel.max(dim=-1, keepdim=True)  # Find max along the last dimension\n",
        "    kernel_max_2, _ = kernel_max_1.max(dim=-2, keepdim=True)  # Find max along the second-to-last dimension\n",
        "    kernel_normalized = kernel / kernel_max_2\n",
        "\n",
        "    kernel_reshaped = kernel_normalized.repeat(1, 3, 1).view(batch_size * 3, kernel_size, kernel_size)\n",
        "    kernel_rgb = kernel_reshaped.unsqueeze(0).reshape(batch_size, 3, kernel_size, kernel_size)\n",
        "\n",
        "    # Calculating the padding needed to match the image size\n",
        "    pad_h = image_size[0] - kernel_size\n",
        "    pad_w = image_size[1] - kernel_size\n",
        "\n",
        "    if pad_h < 0 or pad_w < 0:\n",
        "        raise ValueError(\"Kernel size should be smaller or equal to the image size.\")\n",
        "\n",
        "    # Adding padding to make kernel size equal to the image size\n",
        "    padding = (pad_w // 2, pad_w // 2 + pad_w % 2,  # padding left and right\n",
        "               pad_h // 2, pad_h // 2 + pad_h % 2)  # padding top and bottom\n",
        "\n",
        "    kernel_rgb_padded = torch.nn.functional.pad(kernel_rgb, padding, \"constant\", 0)\n",
        "\n",
        "    # Extracting shape information\n",
        "    b, c, h, w = kernel_rgb_padded.shape\n",
        "\n",
        "    # Create a batch of 2D affine matrices\n",
        "    theta = torch.zeros(b, 2, 3, dtype=torch.float32, device=device)\n",
        "    theta[:, 0, 0] = 1.0\n",
        "    theta[:, 1, 1] = 1.0\n",
        "    theta[:, :, 2] = coords\n",
        "\n",
        "    # Creating grid and performing grid sampling\n",
        "    grid = F.affine_grid(theta, size=(b, c, h, w), align_corners=True)\n",
        "    kernel_rgb_padded_translated = F.grid_sample(kernel_rgb_padded, grid, align_corners=True)\n",
        "\n",
        "    rgb_values_reshaped = colours.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "    final_image_layers = rgb_values_reshaped * kernel_rgb_padded_translated\n",
        "    final_image = final_image_layers.sum(dim=0)\n",
        "    final_image = torch.clamp(final_image, 0, 1)\n",
        "    final_image = final_image.permute(1,2,0)\n",
        "\n",
        "    return final_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GoeRQmOh6ty"
      },
      "source": [
        "# Example usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "tpq6PP1ce8Kb",
        "outputId": "c1932891-76e1-480e-d650-db3a78fd6a54"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "kernel_size = 101  # You can adjust the kernel size as needed\n",
        "rho = torch.tensor([0.0, 0.0, -0.5], device=device)\n",
        "sigma_x = torch.tensor([2.0, 0.5, 0.5], device=device)\n",
        "sigma_y = torch.tensor([2.0, 0.5, 1.5], device=device)\n",
        "vectors = torch.tensor([(-0.5, -0.5), (0.8, 0.8), (0.5, 0.5)], device=device)\n",
        "colours = torch.tensor([(1.0, 0.0, 0.0), (0.0, 1.0, 0.0), (0.0, 0.0, 1.0)], device=device)\n",
        "img_size = (105, 105, 3)\n",
        "\n",
        "final_image = generate_2D_gaussian_splatting(kernel_size, sigma_x, sigma_y, rho, vectors, colours, img_size, device=device)\n",
        "\n",
        "plt.imshow(final_image.detach().cpu().numpy())\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnB8nYi7bliG"
      },
      "source": [
        "## Structural Similarity Index (SSIM) ##\n",
        "This function calculates the combined loss by taking the weighted sum of L1 (mean absolute error) loss and the SSIM-based loss, controlled by lambda_param. This approach might be used to balance the importance of pixel-level accuracy (L1) and perceptual quality (SSIM) in the training of neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoAiMgO52zIl"
      },
      "outputs": [],
      "source": [
        "def create_window(window_size, channel):\n",
        "    def gaussian(window_size, sigma):\n",
        "        gauss = torch.exp(torch.tensor([-(x - window_size//2)**2/float(2*sigma**2) for x in range(window_size)]))\n",
        "        return gauss/gauss.sum()\n",
        "\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = torch.autograd.Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "\n",
        "    return window\n",
        "\n",
        "\n",
        "\n",
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "\n",
        "\n",
        "    # Assuming the image is of shape [N, C, H, W]\n",
        "    (_, _, channel) = img1.size()\n",
        "\n",
        "    img1 = img1.unsqueeze(0).permute(0, 3, 1, 2)\n",
        "    img2 = img2.unsqueeze(0).permute(0, 3, 1, 2)\n",
        "\n",
        "\n",
        "    # Parameters for SSIM\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    window = create_window(window_size, channel)\n",
        "\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2\n",
        "\n",
        "    SSIM_numerator = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))\n",
        "    SSIM_denominator = ((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "    SSIM = SSIM_numerator / SSIM_denominator\n",
        "\n",
        "    return torch.clamp((1 - SSIM) / 2, 0, 1)\n",
        "\n",
        "def d_ssim_loss(img1, img2, window_size=11, size_average=True):\n",
        "    return ssim(img1, img2, window_size, size_average).mean()\n",
        "\n",
        "# Combined Loss\n",
        "def combined_loss(pred, target, lambda_param=0.5):\n",
        "    l1loss = nn.L1Loss()\n",
        "    return (1 - lambda_param) * l1loss(pred, target) + lambda_param * d_ssim_loss(pred, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQtXWcj_sgoh"
      },
      "source": [
        "## Download Data ##\n",
        "This is mainly to make sure the config and image file exist and downloaded from the repository especially if you running it on colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ranC7rJSsgoh"
      },
      "outputs": [],
      "source": [
        "url1 = 'https://raw.githubusercontent.com/OutofAi/2D-Gaussian-Splatting/main/Image-01.png'\n",
        "filename1 = url1.split('/')[-1]\n",
        "response1 = requests.get(url1)\n",
        "with open(filename1, 'wb') as f:\n",
        "    f.write(response1.content)\n",
        "\n",
        "url2 = 'https://raw.githubusercontent.com/OutofAi/2D-Gaussian-Splatting/main/config.yml'\n",
        "filename2 = url2.split('/')[-1]\n",
        "response2 = requests.get(url2)\n",
        "with open(filename2, 'wb') as f:\n",
        "    f.write(response2.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i279V2QJVyN"
      },
      "source": [
        "## Load Config ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkAtK0co4o_R"
      },
      "outputs": [],
      "source": [
        "# Read the config.yml file\n",
        "with open('config.yml', 'r') as config_file:\n",
        "    config = yaml.safe_load(config_file)\n",
        "\n",
        "# Extract values from the loaded config\n",
        "KERNEL_SIZE = config[\"KERNEL_SIZE\"]\n",
        "image_size = tuple(config[\"image_size\"])\n",
        "primary_samples = config[\"primary_samples\"]\n",
        "backup_samples = config[\"backup_samples\"]\n",
        "num_epochs = config[\"num_epochs\"]\n",
        "densification_interval = config[\"densification_interval\"]\n",
        "learning_rate = config[\"learning_rate\"]\n",
        "image_file_name = config[\"image_file_name\"]\n",
        "display_interval = config[\"display_interval\"]\n",
        "grad_threshold = config[\"gradient_threshold\"]\n",
        "gauss_threshold = config[\"gaussian_threshold\"]\n",
        "display_loss = config[\"display_loss\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQsMHUffxVNE"
      },
      "source": [
        "## Prepate the points ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_v9rBeY_j1C"
      },
      "outputs": [],
      "source": [
        "def give_required_data(input_coords, image_size):\n",
        "\n",
        "  # normalising pixel coordinates [-1,1]\n",
        "  coords = torch.tensor(input_coords / [image_size[0],image_size[1]], device=device).float()\n",
        "  center_coords_normalized = torch.tensor([0.5, 0.5], device=device).float()\n",
        "  coords = (center_coords_normalized - coords) * 2.0\n",
        "\n",
        "  # Fetching the colour of the pixels in each coordinates\n",
        "  colour_values = [image_array[coord[1], coord[0]] for coord in input_coords]\n",
        "  colour_values_np = np.array(colour_values)\n",
        "  colour_values_tensor =  torch.tensor(colour_values_np, device=device).float()\n",
        "\n",
        "  return colour_values_tensor, coords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL4PDDwO_lGD"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_samples = primary_samples + backup_samples\n",
        "\n",
        "PADDING = KERNEL_SIZE // 2\n",
        "image_path = image_file_name\n",
        "original_image = Image.open(image_path)\n",
        "original_image = original_image.resize((image_size[0],image_size[0]))\n",
        "original_image = original_image.convert('RGB')\n",
        "original_array = np.array(original_image)\n",
        "original_array = original_array / 255.0\n",
        "width, height, _ = original_array.shape\n",
        "\n",
        "image_array = original_array\n",
        "target_tensor = torch.tensor(image_array, dtype=torch.float32, device=device)\n",
        "coords = np.random.randint(0, [width, height], size=(num_samples, 2))\n",
        "random_pixel_means = torch.tensor(coords, device=device)\n",
        "pixels = [image_array[coord[0], coord[1]] for coord in coords]\n",
        "pixels_np = np.array(pixels)\n",
        "random_pixels =  torch.tensor(pixels_np, device=device)\n",
        "\n",
        "colour_values, pixel_coords = give_required_data(coords, image_size)\n",
        "\n",
        "pixel_coords = torch.atanh(pixel_coords)\n",
        "\n",
        "sigma_values = torch.rand(num_samples, 2, device=device)\n",
        "rho_values = 2 * torch.rand(num_samples, 1, device=device) - 1\n",
        "alpha_values = torch.ones(num_samples, 1, device=device)\n",
        "W_values = torch.cat([sigma_values, rho_values, alpha_values, colour_values, pixel_coords], dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyY0kbHiAaHh"
      },
      "outputs": [],
      "source": [
        "starting_size = primary_samples\n",
        "left_over_size = backup_samples\n",
        "persistent_mask = torch.cat([torch.ones(starting_size, dtype=bool),torch.zeros(left_over_size, dtype=bool)], dim=0)\n",
        "current_marker = starting_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv1odiTTxrIw"
      },
      "outputs": [],
      "source": [
        "# Get current date and time as string\n",
        "now = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "\n",
        "# Create a directory with the current date and time as its name\n",
        "directory = f\"{now}\"\n",
        "os.makedirs(directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwsEfutByA7N"
      },
      "outputs": [],
      "source": [
        "W = nn.Parameter(W_values)\n",
        "optimizer = Adam([W], lr=learning_rate)\n",
        "loss_history = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgFNaM62Lb6g"
      },
      "source": [
        "## Training Loop ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aiadZrbwAdu6",
        "outputId": "59139834-fa57-49af-842b-c985232cc5a4"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #find indices to remove and update the persistent mask\n",
        "    if epoch % (densification_interval + 1) == 0 and epoch > 0:\n",
        "        indices_to_remove = (torch.sigmoid(W[:, 3]) < 0.01).nonzero(as_tuple=True)[0]\n",
        "\n",
        "        if len(indices_to_remove) > 0:\n",
        "          print(f\"number of pruned points: {len(indices_to_remove)}\")\n",
        "\n",
        "        persistent_mask[indices_to_remove] = False\n",
        "\n",
        "        # Zero-out parameters and their gradients at every epoch using the persistent mask\n",
        "        W.data[~persistent_mask] = 0.0\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    output = W[persistent_mask]\n",
        "\n",
        "    batch_size = output.shape[0]\n",
        "\n",
        "    sigma_x = torch.sigmoid(output[:, 0])\n",
        "    sigma_y = torch.sigmoid(output[:, 1])\n",
        "    rho = torch.tanh(output[:, 2])\n",
        "    alpha = torch.sigmoid(output[:, 3])\n",
        "    colours = torch.sigmoid(output[:, 4:7])\n",
        "    pixel_coords = torch.tanh(output[:, 7:9])\n",
        "\n",
        "    colours_with_alpha  = colours * alpha.view(batch_size, 1)\n",
        "    g_tensor_batch = generate_2D_gaussian_splatting(KERNEL_SIZE, sigma_x, sigma_y, rho, pixel_coords, colours_with_alpha, image_size, device)\n",
        "    loss = combined_loss(g_tensor_batch, target_tensor, lambda_param=0.2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # Apply zeroing out of gradients at every epoch\n",
        "    if persistent_mask is not None:\n",
        "        W.grad.data[~persistent_mask] = 0.0\n",
        "\n",
        "    if epoch % densification_interval == 0 and epoch > 0:\n",
        "\n",
        "      # Calculate the norm of gradients\n",
        "      gradient_norms = torch.norm(W.grad[persistent_mask][:, 7:9], dim=1, p=2)\n",
        "      gaussian_norms = torch.norm(torch.sigmoid(W.data[persistent_mask][:, 0:2]), dim=1, p=2)\n",
        "\n",
        "      sorted_grads, sorted_grads_indices = torch.sort(gradient_norms, descending=True)\n",
        "      sorted_gauss, sorted_gauss_indices = torch.sort(gaussian_norms, descending=True)\n",
        "\n",
        "      large_gradient_mask = (sorted_grads > grad_threshold)\n",
        "      large_gradient_indices = sorted_grads_indices[large_gradient_mask]\n",
        "\n",
        "      large_gauss_mask = (sorted_gauss > gauss_threshold)\n",
        "      large_gauss_indices = sorted_gauss_indices[large_gauss_mask]\n",
        "\n",
        "      common_indices_mask = torch.isin(large_gradient_indices, large_gauss_indices)\n",
        "      common_indices = large_gradient_indices[common_indices_mask]\n",
        "      distinct_indices = large_gradient_indices[~common_indices_mask]\n",
        "\n",
        "      # Split points with large coordinate gradient and large gaussian values and descale their gaussian\n",
        "      if len(common_indices) > 0:\n",
        "        print(f\"number of splitted points: {len(common_indices)}\")\n",
        "        start_index = current_marker + 1\n",
        "        end_index = current_marker + 1 + len(common_indices)\n",
        "        persistent_mask[start_index: end_index] = True\n",
        "        W.data[start_index:end_index, :] = W.data[common_indices, :]\n",
        "        scale_reduction_factor = 1.6\n",
        "        W.data[start_index:end_index, 0:2] /= scale_reduction_factor\n",
        "        W.data[common_indices, 0:2] /= scale_reduction_factor\n",
        "        current_marker = current_marker + len(common_indices)\n",
        "\n",
        "      # Clone it points with large coordinate gradient and small gaussian values\n",
        "      if len(distinct_indices) > 0:\n",
        "\n",
        "        print(f\"number of cloned points: {len(distinct_indices)}\")\n",
        "        start_index = current_marker + 1\n",
        "        end_index = current_marker + 1 + len(distinct_indices)\n",
        "        persistent_mask[start_index: end_index] = True\n",
        "        W.data[start_index:end_index, :] = W.data[distinct_indices, :]\n",
        "        current_marker = current_marker + len(distinct_indices)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "    if epoch % display_interval == 0:\n",
        "        num_subplots = 3 if display_loss else 2\n",
        "        fig_size_width = 18 if display_loss else 12\n",
        "\n",
        "        fig, ax = plt.subplots(1, num_subplots, figsize=(fig_size_width, 6))  # Adjust subplot to 1x3\n",
        "\n",
        "        generated_array = g_tensor_batch.cpu().detach().numpy()\n",
        "\n",
        "        ax[0].imshow(g_tensor_batch.cpu().detach().numpy())\n",
        "        ax[0].set_title('2D Gaussian Splatting')\n",
        "        ax[0].axis('off')\n",
        "\n",
        "        ax[1].imshow(target_tensor.cpu().detach().numpy())\n",
        "        ax[1].set_title('Ground Truth')\n",
        "        ax[1].axis('off')\n",
        "\n",
        "        if display_loss:\n",
        "          ax[2].plot(range(epoch + 1), loss_history[:epoch + 1])\n",
        "          ax[2].set_title('Loss vs. Epochs')\n",
        "          ax[2].set_xlabel('Epoch')\n",
        "          ax[2].set_ylabel('Loss')\n",
        "          ax[2].set_xlim(0, num_epochs)  # Set x-axis limits\n",
        "\n",
        "        # Display the image\n",
        "        #plt.show(block=False)\n",
        "        plt.subplots_adjust(wspace=0.1)  # Adjust this value to your preference\n",
        "        plt.pause(0.1)  # Brief pause\n",
        "\n",
        "        img = Image.fromarray((generated_array * 255).astype(np.uint8))\n",
        "\n",
        "        # Create filename\n",
        "        filename = f\"{epoch}.jpg\"\n",
        "\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(directory, filename)\n",
        "\n",
        "        # Save the image\n",
        "        img.save(file_path)\n",
        "\n",
        "        fig.savefig(file_path, bbox_inches='tight')\n",
        "\n",
        "        plt.clf()  # Clear the current figure\n",
        "        plt.close()  # Close the current figure\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, on {len(output)} points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwm6e3_Wsgoj"
      },
      "outputs": [],
      "source": [
        "#Calculate PSNR of the reconstructed image\n",
        "def psnr(img1, img2):\n",
        "    mse = torch.mean((img1 - img2) ** 2)\n",
        "    return 20 * torch.log10(1.0 / torch.sqrt(mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "psnr_value = psnr(g_tensor_batch, target_tensor)\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_compression_ratio(original_image_size, num_gaussians):\n",
        "    # Size of original image in bytes\n",
        "    original_size_bytes = original_image_size[0] * original_image_size[1] * 24 / 8\n",
        "\n",
        "    # Size of compressed image in bytes\n",
        "    compressed_size_bytes = num_gaussians * 9 * 32 / 8\n",
        "\n",
        "    # Compression ratio\n",
        "    compression_ratio = original_size_bytes / compressed_size_bytes\n",
        "\n",
        "    return compression_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compression_ratio = calculate_compression_ratio(image_size, current_marker)\n",
        "compression_ratio"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
